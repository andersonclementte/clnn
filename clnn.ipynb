{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3ac4e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow.compute as pc\n",
    "from torch.utils.data import IterableDataset, DataLoader\n",
    "\n",
    "from external_information import ExternalInformationFusionDTPC, ExternalInformationDense\n",
    "from partial_information import CoordLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d424ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParquetCityDDataset(IterableDataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        parquet_path: str,\n",
    "        city_list: list[str],\n",
    "        chunk_size: int = 10_000\n",
    "    ):\n",
    "        \"\"\"\n",
    "        IterableDataset que lê um Parquet grande em chunks e filtra apenas as\n",
    "        cidades em `city_list`. Retorna para cada amostra:\n",
    "          uid, d, t, city_idx, poi_vector, coords_seq (1,2)\n",
    "        \"\"\"\n",
    "        self.parquet_path = parquet_path\n",
    "        self.city_list    = city_list\n",
    "        self.city_set     = set(city_list)\n",
    "        # mapeia cada letra para um índice 0..len(city_list)-1\n",
    "        self.city_to_idx  = {c: i for i, c in enumerate(city_list)}\n",
    "        self.chunk_size   = chunk_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        pf = pq.ParquetFile(self.parquet_path)\n",
    "        for batch in pf.iter_batches(batch_size=self.chunk_size):\n",
    "            table = pa.Table.from_batches([batch], schema=pf.schema_arrow)\n",
    "\n",
    "            # filtra apenas as cidades permitidas\n",
    "            mask = pc.is_in(table.column(\"city\"), pa.array(list(self.city_set)))\n",
    "            table = table.filter(mask)\n",
    "            if table.num_rows == 0:\n",
    "                continue\n",
    "\n",
    "            # extrai arrays\n",
    "            uid_arr  = table.column(\"uid\").to_numpy().astype(np.int64)\n",
    "            d_arr    = table.column(\"d\"  ).to_numpy().astype(np.int64)\n",
    "            t_arr    = table.column(\"t\"  ).to_numpy().astype(np.int64)\n",
    "            poi_arr  = np.vstack(table.column(\"POI\").to_pylist()).astype(np.float32)\n",
    "            x_arr    = table.column(\"x\").to_numpy().astype(np.float32)\n",
    "            y_arr    = table.column(\"y\").to_numpy().astype(np.float32)\n",
    "            city_arr = table.column(\"city\").to_pylist()\n",
    "            city_idx = np.array([self.city_to_idx[c] for c in city_arr], dtype=np.int64)\n",
    "\n",
    "            # para cada amostra yield\n",
    "            for uid, d, t, cidx, poi, x, y in zip(\n",
    "                uid_arr, d_arr, t_arr, city_idx, poi_arr, x_arr, y_arr\n",
    "            ):\n",
    "                coords_seq = np.array([[x, y]], dtype=np.float32)  # (1,2)\n",
    "                yield (\n",
    "                    torch.tensor(uid, dtype=torch.long),\n",
    "                    torch.tensor(d,   dtype=torch.long),\n",
    "                    torch.tensor(t,   dtype=torch.long),\n",
    "                    torch.tensor(cidx, dtype=torch.long),\n",
    "                    torch.from_numpy(poi),               # (85,)\n",
    "                    torch.from_numpy(coords_seq)         # (1,2)\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ca3150",
   "metadata": {},
   "source": [
    "## Fusão de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ac01273",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedFusion(nn.Module):\n",
    "    \"\"\"\n",
    "    Funde dois vetores de mesmo tamanho (B, dim) por uma soma ponderada:\n",
    "        output = w_r * static_red + w_e * dyn_emb\n",
    "    onde w_r e w_e são parâmetros escalar aprendíveis.\n",
    "    A saída tem a mesma dimensão (dim) dos vetores de entrada.\n",
    "    \"\"\"\n",
    "    def __init__(self, dim: int = 20, init_w_r: float = 0.5, init_w_e: float = 0.5):\n",
    "        super().__init__()\n",
    "        # pesos escalares aprendíveis\n",
    "        self.w_r = nn.Parameter(torch.tensor(init_w_r, dtype=torch.float32))\n",
    "        self.w_e = nn.Parameter(torch.tensor(init_w_e, dtype=torch.float32))\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, static_red: torch.Tensor, dyn_emb: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        static_red: Tensor[B, dim] – vetor reduzido estático\n",
    "        dyn_emb:     Tensor[B, dim] – vetor reduzido dinâmico (LSTM)\n",
    "        retorna:     Tensor[B, dim] – fusão ponderada\n",
    "        \"\"\"\n",
    "        # checa que as dimensões batem\n",
    "        assert static_red.shape == dyn_emb.shape and static_red.size(1) == self.dim\n",
    "        # soma ponderada\n",
    "        fused = self.w_r * static_red + self.w_e * dyn_emb\n",
    "        return fused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0637b16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users_by_city = {\"A\":100_000, \"B\":25_000, \"C\":20_000, \"D\":6_000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b15b2c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "static_red shape: torch.Size([32, 20])\n",
      "dyn_emb    shape: torch.Size([32, 20])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "parquet_file = \"humob_all_cities_dpsk.parquet\"\n",
    "n_users_D    = n_users_by_city[\"D\"]\n",
    "# instantiate models\n",
    "fusion = ExternalInformationFusionDTPC(\n",
    "    n_users=n_users_D,\n",
    "    n_days=75,\n",
    "    n_slots=48,\n",
    "    n_cities=4,\n",
    "    emb_dim=10,\n",
    "    poi_in_dim=85,\n",
    "    poi_out_dim=10\n",
    ")\n",
    "dense = ExternalInformationDense(in_dim=fusion.out_dim, out_dim=20)\n",
    "lstm  = CoordLSTM(input_size=2, hidden_size=10, bidirectional=True)\n",
    "\n",
    "# create dataset + loader\n",
    "ds = ParquetCityDDataset(parquet_file, city_list=[\"D\"], chunk_size=2500)\n",
    "loader = DataLoader(ds, batch_size=32, num_workers=2)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "fusion.to(device); dense.to(device); lstm.to(device)\n",
    "\n",
    "# get one batch and process\n",
    "batch = next(iter(loader))\n",
    "uid, d, t, city, poi, coords_seq = [b.to(device) for b in batch]\n",
    "# static features reduction\n",
    "static_emb = fusion(uid, d, t, city, poi)   # (32, emb*4+poi_out)\n",
    "static_red = dense(static_emb)               # (32, 20)\n",
    "# dynamic LSTM encoding\n",
    "dyn_emb = lstm(coords_seq)                   # (32, 20)\n",
    "\n",
    "print(\"static_red shape:\", static_red.shape)\n",
    "print(\"dyn_emb    shape:\", dyn_emb.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac1ab9a",
   "metadata": {},
   "source": [
    "Os dois pesos passam a ser **parâmetros aprendíveis**, cada um sendo um tensor escalar (shape `()`) com `requires_grad=True`. Veja como eles ficam logo após instanciar:\n",
    "\n",
    "Durante o `optimizer.step()`, tanto `w_r` quanto `w_e` recebem gradientes e são atualizados junto com todos os demais pesos da sua rede. No final do treinamento, seus valores representarão a “importância” relativa que o modelo atribuiu ao vetor estático (`static_red`) versus o vetor dinâmico (`dyn_emb`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ac645b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fused shape: torch.Size([32, 20])\n",
      "w_r = 0.5  w_e = 0.5\n"
     ]
    }
   ],
   "source": [
    "B, dim = 32, 20\n",
    "# static_red = torch.rand(B, dim)\n",
    "# dyn_emb    = torch.rand(B, dim)\n",
    "\n",
    "fusion = WeightedFusion(dim=dim)\n",
    "out = fusion(static_red, dyn_emb)\n",
    "print(\"Fused shape:\", out.shape)  # torch.Size([32, 20])\n",
    "print(\"w_r =\", fusion.w_r.item(), \" w_e =\", fusion.w_e.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6a3650f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DestinationHead(nn.Module):\n",
    "#     \"\"\"\n",
    "#     Head final que,:\n",
    "#       - pega um vetor de dimensão 20,\n",
    "#       - projeta para C logits,\n",
    "#       - softmax → P (B×C),\n",
    "#       - retorna coords finais (B×2) = P @ centers.\n",
    "#     \"\"\"\n",
    "#     def __init__(self, in_dim: int, cluster_centers: torch.Tensor):\n",
    "#         \"\"\"\n",
    "#         in_dim: dimensão de entrada (20)\n",
    "#         cluster_centers: tensor C×2 com as coordenadas dos centros\n",
    "#         \"\"\"\n",
    "#         super().__init__()\n",
    "#         C, coord_dim = cluster_centers.shape\n",
    "#         assert coord_dim == 2\n",
    "#         # linear que vai gerar C e_i's\n",
    "#         self.fc = nn.Linear(in_dim, C, bias=True)\n",
    "#         # inicializa pesos com os centros e bias=0\n",
    "#         with torch.no_grad():\n",
    "#             # fc.weight: [C, in_dim] — queremos usar cada centro (2-vector)\n",
    "#             # mas nossos centros são 2-dim, não in_dim. \n",
    "#             # Em vez disso, faremos outra abordagem: projetar in_dim→C\n",
    "#             # e armazenar centers separadamente:\n",
    "#             self.centers = nn.Parameter(cluster_centers, requires_grad=False)\n",
    "#             # bias em zero\n",
    "#             self.fc.bias.zero_()\n",
    "\n",
    "#     def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "#         \"\"\"\n",
    "#         x: (B, in_dim)\n",
    "#         retorna: (B, 2)\n",
    "#         \"\"\"\n",
    "#         logits = self.fc(x)               # (B, C)\n",
    "#         P      = F.softmax(logits, dim=1) # (B, C)\n",
    "#         # média ponderada dos centros: P @ centers -> (B,2)\n",
    "#         coords = P @ self.centers         # (B,2)\n",
    "#         return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f328717e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP500(nn.Module):\n",
    "    \"\"\"\n",
    "    MLP simples com 1 hidden layer de 500 ReLUs.\n",
    "     - in_dim → 500 → C logits\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim: int, hidden_dim: int, n_clusters: int):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, n_clusters)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: (B, in_dim)\n",
    "        x = F.relu(self.fc1(x))  # (B, hidden_dim)\n",
    "        return self.fc2(x)       # (B, n_clusters)\n",
    "\n",
    "\n",
    "class DestinationHead(nn.Module):\n",
    "    \"\"\"\n",
    "    Combina um MLP500 + softmax + weighted sum pelos cluster centers.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 in_dim: int,           # deve ser 20\n",
    "                 hidden_dim: int,       # 500\n",
    "                 cluster_centers: torch.Tensor  # (C,2)\n",
    "    ):\n",
    "        super().__init__()\n",
    "        C, coord_dim = cluster_centers.shape\n",
    "        assert coord_dim == 2\n",
    "        self.mlp500 = MLP500(in_dim, hidden_dim, C)\n",
    "        # armazenamos centros como buffer (não aprensíveis)\n",
    "        self.register_buffer(\"centers\", cluster_centers)\n",
    "\n",
    "    def forward(self, fused: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        fused: (B, 20) → retorna coords (B,2)\n",
    "        \"\"\"\n",
    "        logits = self.mlp500(fused)        # (B, C)\n",
    "        P      = F.softmax(logits, dim=1)  # (B, C)\n",
    "        # média ponderada: P @ centers → (B,2)\n",
    "        coords = P @ self.centers\n",
    "        return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2567e14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hdbscan  \n",
    "\n",
    "def compute_hdbscan_centers(\n",
    "    parquet_path: str,\n",
    "    city_letter: str = \"D\",\n",
    "    day_threshold: int = 60,\n",
    "    chunk_size: int = 50_000,\n",
    "    min_cluster_size: int = 100\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    1) Lê em chunks o Parquet,\n",
    "    2) filtra city==city_letter e d<day_threshold,\n",
    "    3) acumula destinos (x,y),\n",
    "    4) roda HDBSCAN para descobrir clusters,\n",
    "    5) retorna tensor K×2 com os centros (média dos pontos em cada cluster).\n",
    "    \"\"\"\n",
    "    # 1) coleta todos os destinos de treino da cidade\n",
    "    pf = pq.ParquetFile(parquet_path)\n",
    "    coords_list = []\n",
    "    for batch in pf.iter_batches(batch_size=chunk_size):\n",
    "        tbl = pa.Table.from_batches([batch], schema=pf.schema_arrow)\n",
    "        mask = pc.and_(\n",
    "            pc.equal(tbl.column(\"city\"), city_letter),\n",
    "            pc.less(tbl.column(\"d\"), day_threshold)\n",
    "        )\n",
    "        tbl = tbl.filter(mask)\n",
    "        if tbl.num_rows == 0:\n",
    "            continue\n",
    "        xs = tbl.column(\"x\").to_numpy()\n",
    "        ys = tbl.column(\"y\").to_numpy()\n",
    "        coords_list.append(np.stack([xs, ys], axis=1))\n",
    "    coords = np.vstack(coords_list)  # shape (N,2)\n",
    "\n",
    "    # 2) (opcional) amostra para acelerar\n",
    "    if len(coords) > 200_000:\n",
    "        idx = np.random.choice(len(coords), 200_000, replace=False)\n",
    "        sample = coords[idx]\n",
    "    else:\n",
    "        sample = coords\n",
    "\n",
    "    # 3) roda HDBSCAN\n",
    "    clusterer = hdbscan.HDBSCAN(\n",
    "        min_cluster_size=min_cluster_size,\n",
    "        metric=\"euclidean\",\n",
    "        cluster_selection_method=\"eom\"\n",
    "    )\n",
    "    labels = clusterer.fit_predict(sample)  # shape (M,)\n",
    "\n",
    "    # 4) calcula centros como média de cada cluster\n",
    "    unique_labels = [lab for lab in np.unique(labels) if lab >= 0]\n",
    "    centers = []\n",
    "    for lab in unique_labels:\n",
    "        pts = sample[labels == lab]\n",
    "        centers.append(pts.mean(axis=0))\n",
    "    centers = np.vstack(centers)  # shape (K,2)\n",
    "\n",
    "    return torch.from_numpy(centers.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c6b359d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andersonc/anaconda3/envs/orion_ct/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/andersonc/anaconda3/envs/orion_ct/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 111 clusters\n",
      "z shape: torch.Size([32, 2])\n",
      "Sample coordinates: tensor([[111.0320,  94.4655],\n",
      "        [110.9680,  94.4453],\n",
      "        [110.9077,  94.4409],\n",
      "        [110.8467,  94.5158],\n",
      "        [110.9619,  94.4962]], device='cuda:0', grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "cluster_centers = compute_hdbscan_centers(\n",
    "    parquet_file,\n",
    "    city_letter=\"D\",\n",
    "    day_threshold=60,\n",
    "    chunk_size=50_000,\n",
    "    min_cluster_size=200\n",
    ").to(device)\n",
    "print(f\"Found {cluster_centers.shape[0]} clusters\")\n",
    "\n",
    "# 2) Instantiate head\n",
    "head = DestinationHead(\n",
    "    in_dim=20,\n",
    "    hidden_dim=500,\n",
    "    cluster_centers=cluster_centers\n",
    ").to(device)\n",
    "\n",
    "# 3) Example fused vector (e.g., output of WeightedFusion)\n",
    "# Here `out` should be a tensor of shape (B,20)\n",
    "\n",
    "# 4) Forward final coordinates\n",
    "z = head(out)  # (32,2)\n",
    "print(\"z shape:\", z.shape)\n",
    "print(\"Sample coordinates:\", z[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7def5a6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "orion_ct",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

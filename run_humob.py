"""
Script principal para executar o pipeline completo do HuMob Challenge.

ğŸ†• NOVO: FINE-TUNING IMPLEMENTADO!

CORREÃ‡Ã•ES IMPLEMENTADAS baseadas na anÃ¡lise:
1. âœ… SequÃªncias temporais adequadas (sequence_length > 1) para LSTM fazer sentido
2. âœ… Uso correto da classe ExternalInformationFusionNormalized (dados jÃ¡ normalizados)
3. âœ… Dataset que trabalha com dados jÃ¡ normalizados
4. âœ… Rollout para mÃºltiplos passos (15 dias Ã— 48 slots para HuMob)
5. âœ… DiscretizaÃ§Ã£o final para grid [0,199]
6. âœ… Cluster centers calculados corretamente
7. âœ… Pipeline completo com treino, validaÃ§Ã£o e submissÃ£o
8. ğŸ†• FINE-TUNING sequencial A â†’ B â†’ C â†’ D

PREMISSAS:
- Dados jÃ¡ normalizados conforme especificado:
  * x_norm, y_norm: [0,1] (MinMaxScaler)
  * d_norm: [0,1] (normalizaÃ§Ã£o linear) 
  * t_sin, t_cos: [-1,1] (codificaÃ§Ã£o circular)
  * POI_norm: [0,1] (log1p + normalizaÃ§Ã£o por categoria)
  * city_encoded: {0,1,2,3} (label encoding)
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from tqdm import tqdm
import warnings
import os
warnings.filterwarnings('ignore')

# Importa mÃ³dulos locais (assumindo que estÃ£o no mesmo diretÃ³rio)
try:
    from humob_model import HuMobModel, discretize_coordinates
    from humob_dataset import create_humob_loaders, create_test_loader
    from humob_training import compute_cluster_centers, train_humob_model, evaluate_model
    from humob_pipeline import run_full_pipeline, generate_humob_submission
    from humob_finetuning import finetune_model, sequential_finetuning, compare_models_performance  # ğŸ†• NOVO!
except ImportError as e:
    print(f"âŒ Erro importando mÃ³dulos: {e}")
    print("ğŸ“‹ Certifique-se de que os arquivos estÃ£o no mesmo diretÃ³rio:")
    print("   - external_information.py")
    print("   - partial_information.py") 
    print("   - humob_model.py")
    print("   - humob_dataset.py")
    print("   - humob_training.py (CORRIGIDO)")
    print("   - humob_pipeline.py (CORRIGIDO)")
    print("   - humob_finetuning.py (NOVO)")
    exit(1)


def quick_test(parquet_path: str, device: torch.device):
    """Teste rÃ¡pido para verificar se o pipeline estÃ¡ funcionando."""
    print("ğŸ§ª TESTE RÃPIDO DO PIPELINE")
    print("=" * 40)
    
    try:
        # 1. Testa cluster centers
        print("1. Testando cÃ¡lculo de cluster centers...")
        centers = compute_cluster_centers(
            parquet_path=parquet_path,
            cities=["A"],
            n_clusters=64,  # Pequeno para teste
            sample_size=10000,
            save_path="test_centers.npy"
        )
        print(f"   âœ… Centers: {centers.shape}")
        
        # 2. Testa criaÃ§Ã£o de dataset
        print("2. Testando dataset...")
        train_loader, val_loader = create_humob_loaders(
            parquet_path=parquet_path,
            cities=["A"],
            batch_size=16,
            sequence_length=6  # Pequeno para teste
        )
        
        # Tenta uma amostra
        for batch in train_loader:
            uid, d_norm, t_sin, t_cos, city, poi_norm, coords_seq, target_coords = batch
            print(f"   âœ… Batch shape: {coords_seq.shape}")
            print(f"   âœ… Ranges: d_norm=[{d_norm.min():.3f},{d_norm.max():.3f}], "
                  f"coords=[{coords_seq.min():.3f},{coords_seq.max():.3f}]")
            break
        
        # 3. Testa modelo
        print("3. Testando modelo...")
        model = HuMobModel(
            n_users=1000,  # Pequeno para teste
            n_cities=4,
            cluster_centers=centers.to(device),
            sequence_length=6
        ).to(device)
        
        # Forward test
        with torch.no_grad():
            uid_test = torch.randint(0, 1000, (2,), device=device)
            d_norm_test = torch.rand(2, device=device)
            t_sin_test = torch.randn(2, device=device)
            t_cos_test = torch.randn(2, device=device)
            city_test = torch.randint(0, 4, (2,), device=device)
            poi_test = torch.rand(2, 85, device=device)
            coords_seq_test = torch.rand(2, 6, 2, device=device)
            
            pred = model.forward_single_step(
                uid_test, d_norm_test, t_sin_test, t_cos_test,
                city_test, poi_test, coords_seq_test
            )
            print(f"   âœ… PrediÃ§Ã£o shape: {pred.shape}")
            print(f"   âœ… PrediÃ§Ã£o range: [{pred.min():.3f}, {pred.max():.3f}]")
        
        print("\nğŸ‰ TESTE RÃPIDO PASSOU! Pipeline estÃ¡ funcionando.")
        return True
        
    except Exception as e:
        print(f"\nâŒ TESTE RÃPIDO FALHOU: {e}")
        import traceback
        traceback.print_exc()
        return False


def run_minimal_example(parquet_path: str):
    """Executa um exemplo mÃ­nimo para demonstraÃ§Ã£o."""
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    print("ğŸš€ EXEMPLO MÃNIMO HUMOB")
    print(f"Device: {device}")
    print("=" * 40)
    
    # Teste rÃ¡pido primeiro
    if not quick_test(parquet_path, device):
        print("âŒ Teste rÃ¡pido falhou. Verifique os dados e imports.")
        return None
    
    print("\nğŸƒ Executando pipeline mÃ­nimo...")
    
    # Pipeline com configuraÃ§Ãµes mÃ­nimas
    results = run_full_pipeline(
        parquet_path=parquet_path,
        device=device,
        n_clusters=128,     # Reduzido
        n_epochs=2,        # Poucas Ã©pocas 
        sequence_length=8,  # HistÃ³rico pequeno
        batch_size=32,
        learning_rate=2e-3,
        n_users_A=100_000
    )
    
    if results and results.get('checkpoint_path'):
        print("\nğŸ“„ Gerando submissÃ£o de exemplo...")
        try:
            submission_df = generate_humob_submission(
                parquet_path=parquet_path,
                checkpoint_path=results['checkpoint_path'],
                device=device,
                target_cities=["D"],  # Apenas cidade D para teste
                submission_days=(61, 62),  # Apenas 2 dias para teste
                sequence_length=8,
                output_file="humob_example_submission.csv"
            )
            print(f"âœ… SubmissÃ£o de exemplo gerada: {len(submission_df):,} linhas")
        except Exception as e:
            print(f"âš ï¸ Erro na submissÃ£o: {e}")
    
    return results


def run_full_competition(parquet_path: str):
    """Executa o pipeline completo para competiÃ§Ã£o."""
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    print("ğŸ† PIPELINE COMPLETO PARA COMPETIÃ‡ÃƒO")
    print(f"Device: {device}")
    print("=" * 50)
    
    # ConfiguraÃ§Ãµes otimizadas para competiÃ§Ã£o
    results = run_full_pipeline(
        parquet_path=parquet_path,
        device=device,
        n_clusters=512,      # Mais centros para melhor precisÃ£o
        n_epochs=8,         # Mais Ã©pocas
        sequence_length=24,  # Mais histÃ³rico (12 horas)
        batch_size=64,
        learning_rate=1e-3,
        n_users_A=100_000
    )
    
    if results and results.get('checkpoint_path'):
        print("\nğŸ“„ Gerando submissÃ£o final...")
        submission_df = generate_humob_submission(
            parquet_path=parquet_path,
            checkpoint_path=results['checkpoint_path'],
            device=device,
            target_cities=["B", "C", "D"],
            submission_days=(61, 75),  # 15 dias completos
            sequence_length=24,
            output_file="humob_final_submission.csv"
        )
        print(f"ğŸ¯ SubmissÃ£o final: {len(submission_df):,} prediÃ§Ãµes")
        print("ğŸ“§ Pronto para envio ao HuMob Challenge!")
    
    return results


def run_finetuning_example(parquet_path: str):
    """ğŸ†• NOVO: Executa fine-tuning sequencial."""
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    print("ğŸ¯ FINE-TUNING SEQUENCIAL HUMOB")
    print(f"Device: {device}")
    print("=" * 50)
    
    # Verifica se modelo base existe
    base_model = "humob_model_A.pt"
    if not os.path.exists(base_model):
        print(f"âŒ Modelo base nÃ£o encontrado: {base_model}")
        print("Execute primeiro a opÃ§Ã£o 2 ou 3 para treinar o modelo base em A")
        return None
    
    print(f"ğŸ“‚ Modelo base encontrado: {base_model}")
    
    # Fine-tuning sequencial com configuraÃ§Ãµes moderadas
    results = sequential_finetuning(
        parquet_path=parquet_path,
        base_checkpoint=base_model,
        cities=["B", "C", "D"],
        device=device,
        n_epochs_per_city=3,        # 3 Ã©pocas por cidade
        learning_rate=5e-5,         # LR bem baixo para fine-tuning
        sequence_length=24
    )
    
    # ComparaÃ§Ã£o de performance
    successful = sum(1 for r in results.values() if r['status'] == 'success')
    if successful > 0:
        print(f"\nğŸ” COMPARANDO PERFORMANCE...")
        
        # Monta lista de checkpoints para comparar
        checkpoints = {'Zero-shot (A apenas)': base_model}
        
        for city, result in results.items():
            if result['status'] == 'success':
                checkpoints[f'Fine-tuned {city}'] = result['checkpoint']
        
        comparison = compare_models_performance(
            parquet_path=parquet_path,
            checkpoints=checkpoints,
            device=device,
            n_samples=2000  # Amostra menor para ser mais rÃ¡pido
        )
        
        # Se o fine-tuning foi bem-sucedido, oferece gerar submissÃ£o
        if successful == len(["B", "C", "D"]):
            print(f"\nğŸ‰ FINE-TUNING COMPLETO!")
            
            response = input("\nğŸ“„ Gerar submissÃ£o com modelos fine-tuned? (y/n): ").strip().lower()
            if response == 'y':
                # Gera submissÃ£o usando modelo da Ãºltima cidade (D)
                final_checkpoint = results["D"]["checkpoint"]
                submission_df = generate_humob_submission(
                    parquet_path=parquet_path,
                    checkpoint_path=final_checkpoint,
                    device=device,
                    target_cities=["B", "C", "D"],
                    submission_days=(61, 75),
                    sequence_length=24,
                    output_file="humob_finetuned_submission.csv"
                )
                print(f"âœ… SubmissÃ£o fine-tuned gerada: {len(submission_df):,} prediÃ§Ãµes")
    
    return results


def run_single_city_finetuning(parquet_path: str):
    """ğŸ†• NOVO: Fine-tuning em uma cidade especÃ­fica."""
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    print("ğŸ¯ FINE-TUNING CIDADE ESPECÃFICA")
    print("=" * 40)
    
    # Verifica modelo base
    base_model = "humob_model_A.pt"
    if not os.path.exists(base_model):
        print(f"âŒ Modelo base nÃ£o encontrado: {base_model}")
        print("Execute primeiro a opÃ§Ã£o 2 ou 3 para treinar o modelo base em A")
        return None
    
    # Seleciona cidade
    print("Cidades disponÃ­veis para fine-tuning: B, C, D")
    city = input("Digite a cidade (B/C/D): ").strip().upper()
    
    if city not in ["B", "C", "D"]:
        print("âŒ Cidade invÃ¡lida")
        return None
    
    print(f"ğŸ¯ Iniciando fine-tuning na cidade {city}...")
    
    # Fine-tuning
    try:
        model, train_losses, val_losses = finetune_model(
            parquet_path=parquet_path,
            pretrained_checkpoint=base_model,
            target_city=city,
            device=device,
            n_epochs=1,
            learning_rate=5e-5,
            sequence_length=24
        )
        
        print(f"\nâœ… Fine-tuning cidade {city} concluÃ­do!")
        
        # Compara com zero-shot
        checkpoints = {
            'Zero-shot (A apenas)': base_model,
            f'Fine-tuned {city}': f'humob_model_finetuned_{city}.pt'
        }
        
        comparison = compare_models_performance(
            parquet_path=parquet_path,
            checkpoints=checkpoints,
            test_cities=[city],
            device=device,
            n_samples=3000
        )
        
        return {
            'city': city,
            'model': model,
            'train_losses': train_losses,
            'val_losses': val_losses,
            'checkpoint': f'humob_model_finetuned_{city}.pt',
            'comparison': comparison
        }
        
    except Exception as e:
        print(f"âŒ Erro durante fine-tuning: {e}")
        import traceback
        traceback.print_exc()
        return None


def main():
    """FunÃ§Ã£o principal com menu interativo ATUALIZADO."""
    
    # ConfiguraÃ§Ã£o do arquivo (AJUSTE AQUI)
    parquet_file = "humob_all_cities_v2_normalized.parquet"
    
    print("ğŸ¯ HUMOB CHALLENGE - PIPELINE COM FINE-TUNING")
    print("=" * 60)
    print("ğŸ†• Fine-tuning implementado!")
    print()
    print("CorreÃ§Ãµes implementadas:")
    print("âœ… SequÃªncias temporais adequadas (LSTM funcional)")
    print("âœ… Dados normalizados [0,1] / [-1,1]") 
    print("âœ… Rollout para mÃºltiplos passos")
    print("âœ… DiscretizaÃ§Ã£o para grid [0,199]")
    print("âœ… Pipeline completo treino â†’ submissÃ£o")
    print("ğŸ†• Fine-tuning sequencial A â†’ B â†’ C â†’ D")
    print()
    
    if not os.path.exists(parquet_file):
        print(f"âŒ Arquivo nÃ£o encontrado: {parquet_file}")
        print("ğŸ“‹ Certifique-se de:")
        print("   1. Ter executado a normalizaÃ§Ã£o dos dados")
        print("   2. O arquivo ter as colunas corretas:")
        print("      - uid, city_encoded, d_norm, t_sin, t_cos")
        print("      - x_norm, y_norm, POI_norm")
        return
    
    print(f"ğŸ“ Arquivo encontrado: {parquet_file}")
    print()
    
    # Menu ATUALIZADO
    print("Escolha uma opÃ§Ã£o:")
    print("1. ğŸ§ª Teste rÃ¡pido (verifica se tudo estÃ¡ funcionando)")
    print("2. ğŸƒ Exemplo mÃ­nimo (pipeline pequeno para demonstraÃ§Ã£o)")  
    print("3. ğŸ† Pipeline completo (para submissÃ£o final)")
    print("4. ğŸ¯ Fine-tuning sequencial Bâ†’Câ†’D")
    print("5. ğŸª Fine-tuning cidade especÃ­fica")
    print("6. ğŸ” Avaliar modelos existentes (sem treinar)")
    
    try:
        choice = input("\nDigite sua escolha (1-6): ").strip()
        
        if choice == "1":
            device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
            quick_test(parquet_file, device)
            
        elif choice == "2":
            run_minimal_example(parquet_file)
            
        elif choice == "3":
            run_full_competition(parquet_file)
            
        elif choice == "4":
            run_finetuning_example(parquet_file)
            
        elif choice == "5":
            run_single_city_finetuning(parquet_file)
            
        elif choice == "6":
            # Avalia modelos existentes
            device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
            
            # Busca modelos disponÃ­veis
            checkpoints = {}
            
            if os.path.exists("humob_model_A.pt"):
                checkpoints['Zero-shot (A apenas)'] = "humob_model_A.pt"
            
            for city in ["B", "C", "D"]:
                checkpoint = f"humob_model_finetuned_{city}.pt"
                if os.path.exists(checkpoint):
                    checkpoints[f'Fine-tuned {city}'] = checkpoint
            
            if not checkpoints:
                print("âŒ Nenhum modelo encontrado. Execute treino primeiro.")
            else:
                print(f"ğŸ“Š Encontrados {len(checkpoints)} modelos:")
                for name in checkpoints:
                    print(f"   - {name}")
                
                comparison = compare_models_performance(
                    parquet_path=parquet_file,
                    checkpoints=checkpoints,
                    device=device,
                    n_samples=3000
                )
            
        else:
            print("âŒ OpÃ§Ã£o invÃ¡lida")
            
    except KeyboardInterrupt:
        print("\nğŸ›‘ ExecuÃ§Ã£o interrompida pelo usuÃ¡rio")
    except Exception as e:
        print(f"\nâŒ Erro durante execuÃ§Ã£o: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
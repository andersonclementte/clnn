"""
Script principal para executar o pipeline completo do HuMob Challenge.

CORRE√á√ïES IMPLEMENTADAS baseadas na an√°lise:
1. ‚úÖ Sequ√™ncias temporais adequadas (sequence_length > 1) para LSTM fazer sentido
2. ‚úÖ Uso correto da classe ExternalInformationFusionNormalized (dados j√° normalizados)
3. ‚úÖ Dataset que trabalha com dados j√° normalizados
4. ‚úÖ Rollout para m√∫ltiplos passos (15 dias √ó 48 slots para HuMob)
5. ‚úÖ Discretiza√ß√£o final para grid [0,199]
6. ‚úÖ Cluster centers calculados corretamente
7. ‚úÖ Pipeline completo com treino, valida√ß√£o e submiss√£o

PREMISSAS:
- Dados j√° normalizados conforme especificado:
  * x_norm, y_norm: [0,1] (MinMaxScaler)
  * d_norm: [0,1] (normaliza√ß√£o linear) 
  * t_sin, t_cos: [-1,1] (codifica√ß√£o circular)
  * POI_norm: [0,1] (log1p + normaliza√ß√£o por categoria)
  * city_encoded: {0,1,2,3} (label encoding)
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from tqdm import tqdm
import warnings
import os
warnings.filterwarnings('ignore')

# Importa m√≥dulos locais (assumindo que est√£o no mesmo diret√≥rio)
try:
    from humob_model import HuMobModel, discretize_coordinates
    from humob_dataset import create_humob_loaders, create_test_loader
    from humob_training import compute_cluster_centers, train_humob_model, evaluate_model
    from humob_pipeline import run_full_pipeline, generate_humob_submission
except ImportError as e:
    print(f"‚ùå Erro importando m√≥dulos: {e}")
    print("üìã Certifique-se de que os arquivos est√£o no mesmo diret√≥rio:")
    print("   - external_information.py")
    print("   - partial_information.py") 
    print("   - humob_model.py")
    print("   - humob_dataset.py")
    print("   - humob_training.py")
    print("   - humob_pipeline.py")
    exit(1)


def quick_test(parquet_path: str, device: torch.device):
    """Teste r√°pido para verificar se o pipeline est√° funcionando."""
    print("üß™ TESTE R√ÅPIDO DO PIPELINE")
    print("=" * 40)
    
    try:
        # 1. Testa cluster centers
        print("1. Testando c√°lculo de cluster centers...")
        centers = compute_cluster_centers(
            parquet_path=parquet_path,
            cities=["A"],
            n_clusters=64,  # Pequeno para teste
            sample_size=10000,
            save_path="test_centers.npy"
        )
        print(f"   ‚úÖ Centers: {centers.shape}")
        
        # 2. Testa cria√ß√£o de dataset
        print("2. Testando dataset...")
        train_loader, val_loader = create_humob_loaders(
            parquet_path=parquet_path,
            cities=["A"],
            batch_size=16,
            sequence_length=6  # Pequeno para teste
        )
        
        # Tenta uma amostra
        for batch in train_loader:
            uid, d_norm, t_sin, t_cos, city, poi_norm, coords_seq, target_coords = batch
            print(f"   ‚úÖ Batch shape: {coords_seq.shape}")
            print(f"   ‚úÖ Ranges: d_norm=[{d_norm.min():.3f},{d_norm.max():.3f}], "
                  f"coords=[{coords_seq.min():.3f},{coords_seq.max():.3f}]")
            break
        
        # 3. Testa modelo
        print("3. Testando modelo...")
        model = HuMobModel(
            n_users=1000,  # Pequeno para teste
            n_cities=4,
            cluster_centers=centers.to(device),
            sequence_length=6
        ).to(device)
        
        # Forward test
        with torch.no_grad():
            uid_test = torch.randint(0, 1000, (2,), device=device)
            d_norm_test = torch.rand(2, device=device)
            t_sin_test = torch.randn(2, device=device)
            t_cos_test = torch.randn(2, device=device)
            city_test = torch.randint(0, 4, (2,), device=device)
            poi_test = torch.rand(2, 85, device=device)
            coords_seq_test = torch.rand(2, 6, 2, device=device)
            
            pred = model.forward_single_step(
                uid_test, d_norm_test, t_sin_test, t_cos_test,
                city_test, poi_test, coords_seq_test
            )
            print(f"   ‚úÖ Predi√ß√£o shape: {pred.shape}")
            print(f"   ‚úÖ Predi√ß√£o range: [{pred.min():.3f}, {pred.max():.3f}]")
        
        print("\nüéâ TESTE R√ÅPIDO PASSOU! Pipeline est√° funcionando.")
        return True
        
    except Exception as e:
        print(f"\n‚ùå TESTE R√ÅPIDO FALHOU: {e}")
        import traceback
        traceback.print_exc()
        return False


def run_minimal_example(parquet_path: str):
    """Executa um exemplo m√≠nimo para demonstra√ß√£o."""
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    print("üöÄ EXEMPLO M√çNIMO HUMOB")
    print(f"Device: {device}")
    print("=" * 40)
    
    # Teste r√°pido primeiro
    if not quick_test(parquet_path, device):
        print("‚ùå Teste r√°pido falhou. Verifique os dados e imports.")
        return None
    
    print("\nüèÉ Executando pipeline m√≠nimo...")
    
    # Pipeline com configura√ß√µes m√≠nimas
    results = run_full_pipeline(
        parquet_path=parquet_path,
        device=device,
        n_clusters=128,     # Reduzido
        n_epochs=2,        # Poucas √©pocas 
        sequence_length=8,  # Hist√≥rico pequeno
        batch_size=32,
        learning_rate=2e-3,
        n_users_A=100_000
    )
    
    if results and results.get('checkpoint_path'):
        print("\nüìÑ Gerando submiss√£o de exemplo...")
        try:
            submission_df = generate_humob_submission(
                parquet_path=parquet_path,
                checkpoint_path=results['checkpoint_path'],
                device=device,
                target_cities=["D"],  # Apenas cidade D para teste
                submission_days=(61, 62),  # Apenas 2 dias para teste
                sequence_length=8,
                output_file="humob_example_submission.csv"
            )
            print(f"‚úÖ Submiss√£o de exemplo gerada: {len(submission_df):,} linhas")
        except Exception as e:
            print(f"‚ö†Ô∏è Erro na submiss√£o: {e}")
    
    return results


def run_full_competition(parquet_path: str):
    """Executa o pipeline completo para competi√ß√£o."""
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    print("üèÜ PIPELINE COMPLETO PARA COMPETI√á√ÉO")
    print(f"Device: {device}")
    print("=" * 50)
    
    # Configura√ß√µes otimizadas para competi√ß√£o
    results = run_full_pipeline(
        parquet_path=parquet_path,
        device=device,
        n_clusters=512,      # Mais centros para melhor precis√£o
        n_epochs=8,         # Mais √©pocas
        sequence_length=24,  # Mais hist√≥rico (12 horas)
        batch_size=64,
        learning_rate=1e-3,
        n_users_A=100_000
    )
    
    if results and results.get('checkpoint_path'):
        print("\nüìÑ Gerando submiss√£o final...")
        submission_df = generate_humob_submission(
            parquet_path=parquet_path,
            checkpoint_path=results['checkpoint_path'],
            device=device,
            target_cities=["B", "C", "D"],
            submission_days=(61, 75),  # 15 dias completos
            sequence_length=24,
            output_file="humob_final_submission.csv"
        )
        print(f"üéØ Submiss√£o final: {len(submission_df):,} predi√ß√µes")
        print("üìß Pronto para envio ao HuMob Challenge!")
    
    return results


def main():
    """Fun√ß√£o principal com menu interativo."""
    
    # Configura√ß√£o do arquivo (AJUSTE AQUI)
    parquet_file = "humob_all_cities_v2_normalized.parquet"
    
    print("üéØ HUMOB CHALLENGE - PIPELINE CORRIGIDO")
    print("=" * 50)
    print("Corre√ß√µes implementadas:")
    print("‚úÖ Sequ√™ncias temporais adequadas (LSTM funcional)")
    print("‚úÖ Dados normalizados [0,1] / [-1,1]") 
    print("‚úÖ Rollout para m√∫ltiplos passos")
    print("‚úÖ Discretiza√ß√£o para grid [0,199]")
    print("‚úÖ Pipeline completo treino ‚Üí submiss√£o")
    print()
    
    if not os.path.exists(parquet_file):
        print(f"‚ùå Arquivo n√£o encontrado: {parquet_file}")
        print("üìã Certifique-se de:")
        print("   1. Ter executado a normaliza√ß√£o dos dados")
        print("   2. O arquivo ter as colunas corretas:")
        print("      - uid, city_encoded, d_norm, t_sin, t_cos")
        print("      - x_norm, y_norm, POI_norm")
        return
    
    print(f"üìÅ Arquivo encontrado: {parquet_file}")
    print()
    
    # Menu
    print("Escolha uma op√ß√£o:")
    print("1. üß™ Teste r√°pido (verifica se tudo est√° funcionando)")
    print("2. üèÉ Exemplo m√≠nimo (pipeline pequeno para demonstra√ß√£o)")  
    print("3. üèÜ Pipeline completo (para submiss√£o final)")
    
    try:
        choice = input("\nDigite sua escolha (1-3): ").strip()
        
        if choice == "1":
            device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
            quick_test(parquet_file, device)
            
        elif choice == "2":
            run_minimal_example(parquet_file)
            
        elif choice == "3":
            run_full_competition(parquet_file)
            
        else:
            print("‚ùå Op√ß√£o inv√°lida")
            
    except KeyboardInterrupt:
        print("\nüõë Execu√ß√£o interrompida pelo usu√°rio")
    except Exception as e:
        print(f"\n‚ùå Erro durante execu√ß√£o: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()